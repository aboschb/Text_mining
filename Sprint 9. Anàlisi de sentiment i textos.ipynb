{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfefb7bc",
   "metadata": {},
   "source": [
    "# Exercici 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35349d45",
   "metadata": {},
   "source": [
    "<b> Agafa un text en anglès que vulguis i calcula'n la freqüència de les paraules. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce3dca",
   "metadata": {},
   "source": [
    "Hem escollit el següent article:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8701c2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">What is data science?</p>\n",
    "\n",
    "*Data science combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI), and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organization’s data. These insights can be used to guide decision making and strategic planning.*\n",
    "\n",
    "*The accelerating volume of data sources, and subsequently data, has made data science is one of the fastest growing field across every industry. As a result, it is no surprise that the role of the data scientist was dubbed the “sexiest job of the 21st century” by Harvard Business Review (link resides outside of IBM). Organizations are increasingly reliant on them to interpret data and provide actionable recommendations to improve business outcomes.*\n",
    "\n",
    "*The data science lifecycle involves various roles, tools, and processes, which enables analysts to glean actionable insights. Typically, a data science project undergoes the following stages:*\n",
    "\n",
    "*Data ingestion: The lifecycle begins with the data collection--both raw structured and unstructured data from all relevant sources using a variety of methods. These methods can include manual entry, web scraping, and real-time streaming data from systems and devices. Data sources can include structured data, such as customer data, along with unstructured data like log files, video, audio, pictures, the Internet of Things (IoT), social media, and more.*\n",
    "\n",
    "*Data storage and data processing: Since data can have different formats and structures, companies need to consider different storage systems based on the type of data that needs to be captured. Data management teams help to set standards around data storage and structure, which facilitate workflows around analytics, machine learning and deep learning models. This stage includes cleaning data, deduplicating, transforming and combining the data using ETL (extract, transform, load) jobs or other data integration technologies. This data preparation is essential for promoting data quality before loading into a data warehouse, data lake, or other repository.*\n",
    "\n",
    "*Data analysis: Here, data scientists conduct an exploratory data analysis to examine biases, patterns, ranges, and distributions of values within the data. This data analytics exploration drives hypothesis generation for a/b testing. It also allows analysts to determine the data’s relevance for use within modeling efforts for predictive analytics, machine learning, and/or deep learning. Depending on a model’s accuracy, organizations can become reliant on these insights for business decision making, allowing them to drive more scalability.*\n",
    "\n",
    "*Communicate: Finally, insights are presented as reports and other data visualizations that make the insights—and their impact on business—easier for business analysts and other decision-makers to understand. A data science programming language such as R or Python includes components for generating visualizations; alternately, data scientists can use dedicated visualization tools.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9783856",
   "metadata": {},
   "source": [
    "Enllaç: https://www.ibm.com/topics/data-science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eee826",
   "metadata": {},
   "source": [
    "En primer lloc assignem el text a una variable. Alternativament podríem llegir el text des de l'enllaç, mitjançant llibreries com 'requests' per obtenir el contingut de la pàgina i 'BeautifulSoup' per a parsejar el contingut HTML i extreure'n el text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc03c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"What is data science?\n",
    "\n",
    "Data science combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI), and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organization’s data. These insights can be used to guide decision making and strategic planning.\n",
    "\n",
    "The accelerating volume of data sources, and subsequently data, has made data science is one of the fastest growing field across every industry. As a result, it is no surprise that the role of the data scientist was dubbed the “sexiest job of the 21st century” by Harvard Business Review (link resides outside of IBM). Organizations are increasingly reliant on them to interpret data and provide actionable recommendations to improve business outcomes.\n",
    "\n",
    "The data science lifecycle involves various roles, tools, and processes, which enables analysts to glean actionable insights. Typically, a data science project undergoes the following stages:\n",
    "\n",
    "Data ingestion: The lifecycle begins with the data collection--both raw structured and unstructured data from all relevant sources using a variety of methods. These methods can include manual entry, web scraping, and real-time streaming data from systems and devices. Data sources can include structured data, such as customer data, along with unstructured data like log files, video, audio, pictures, the Internet of Things (IoT), social media, and more.\n",
    "\n",
    "Data storage and data processing: Since data can have different formats and structures, companies need to consider different storage systems based on the type of data that needs to be captured. Data management teams help to set standards around data storage and structure, which facilitate workflows around analytics, machine learning and deep learning models. This stage includes cleaning data, deduplicating, transforming and combining the data using ETL (extract, transform, load) jobs or other data integration technologies. This data preparation is essential for promoting data quality before loading into a data warehouse, data lake, or other repository.\n",
    "\n",
    "Data analysis: Here, data scientists conduct an exploratory data analysis to examine biases, patterns, ranges, and distributions of values within the data. This data analytics exploration drives hypothesis generation for a/b testing. It also allows analysts to determine the data’s relevance for use within modeling efforts for predictive analytics, machine learning, and/or deep learning. Depending on a model’s accuracy, organizations can become reliant on these insights for business decision making, allowing them to drive more scalability.\n",
    "\n",
    "Communicate: Finally, insights are presented as reports and other data visualizations that make the insights—and their impact on business—easier for business analysts and other decision-makers to understand. A data science programming language such as R or Python includes components for generating visualizations; alternately, data scientists can use dedicated visualization tools.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c27c10",
   "metadata": {},
   "source": [
    "Ara farem un anàlisi de la freqüència de paraules del text, tal i com demana l'exercici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51048d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what : 1\n",
      "is : 4\n",
      "data : 40\n",
      "science : 6\n",
      "? : 1\n",
      "combines : 1\n",
      "math : 1\n",
      "and : 18\n",
      "statistics : 1\n",
      ", : 40\n",
      "specialized : 1\n",
      "programming : 2\n",
      "advanced : 1\n",
      "analytics : 4\n",
      "artificial : 1\n",
      "intelligence : 1\n",
      "( : 4\n",
      "ai : 1\n",
      ") : 4\n",
      "machine : 3\n",
      "learning : 5\n",
      "with : 3\n",
      "specific : 1\n",
      "subject : 1\n",
      "matter : 1\n",
      "expertise : 1\n",
      "to : 12\n",
      "uncover : 1\n",
      "actionable : 3\n",
      "insights : 5\n",
      "hidden : 1\n",
      "in : 1\n",
      "an : 2\n",
      "organization : 1\n",
      "’ : 3\n",
      "s : 3\n",
      ". : 19\n",
      "these : 3\n",
      "can : 6\n",
      "be : 2\n",
      "used : 1\n",
      "guide : 1\n",
      "decision : 2\n",
      "making : 2\n",
      "strategic : 1\n",
      "planning : 1\n",
      "the : 16\n",
      "accelerating : 1\n",
      "volume : 1\n",
      "of : 9\n",
      "sources : 3\n",
      "subsequently : 1\n",
      "has : 1\n",
      "made : 1\n",
      "one : 1\n",
      "fastest : 1\n",
      "growing : 1\n",
      "field : 1\n",
      "across : 1\n",
      "every : 1\n",
      "industry : 1\n",
      "as : 4\n",
      "a : 6\n",
      "result : 1\n",
      "it : 2\n",
      "no : 1\n",
      "surprise : 1\n",
      "that : 3\n",
      "role : 1\n",
      "scientist : 1\n",
      "was : 1\n",
      "dubbed : 1\n",
      "“ : 1\n",
      "sexiest : 1\n",
      "job : 1\n",
      "21st : 1\n",
      "century : 1\n",
      "” : 1\n",
      "by : 1\n",
      "harvard : 1\n",
      "business : 4\n",
      "review : 1\n",
      "link : 1\n",
      "resides : 1\n",
      "outside : 1\n",
      "ibm : 1\n",
      "organizations : 2\n",
      "are : 2\n",
      "increasingly : 1\n",
      "reliant : 2\n",
      "on : 5\n",
      "them : 2\n",
      "interpret : 1\n",
      "provide : 1\n",
      "recommendations : 1\n",
      "improve : 1\n",
      "outcomes : 1\n",
      "lifecycle : 2\n",
      "involves : 1\n",
      "various : 1\n",
      "roles : 1\n",
      "tools : 2\n",
      "processes : 1\n",
      "which : 2\n",
      "enables : 1\n",
      "analysts : 3\n",
      "glean : 1\n",
      "typically : 1\n",
      "project : 1\n",
      "undergoes : 1\n",
      "following : 1\n",
      "stages : 1\n",
      ": : 5\n",
      "ingestion : 1\n",
      "begins : 1\n",
      "collection : 1\n",
      "-- : 1\n",
      "both : 1\n",
      "raw : 1\n",
      "structured : 2\n",
      "unstructured : 2\n",
      "from : 2\n",
      "all : 1\n",
      "relevant : 1\n",
      "using : 2\n",
      "variety : 1\n",
      "methods : 2\n",
      "include : 2\n",
      "manual : 1\n",
      "entry : 1\n",
      "web : 1\n",
      "scraping : 1\n",
      "real-time : 1\n",
      "streaming : 1\n",
      "systems : 2\n",
      "devices : 1\n",
      "such : 2\n",
      "customer : 1\n",
      "along : 1\n",
      "like : 1\n",
      "log : 1\n",
      "files : 1\n",
      "video : 1\n",
      "audio : 1\n",
      "pictures : 1\n",
      "internet : 1\n",
      "things : 1\n",
      "iot : 1\n",
      "social : 1\n",
      "media : 1\n",
      "more : 2\n",
      "storage : 3\n",
      "processing : 1\n",
      "since : 1\n",
      "have : 1\n",
      "different : 2\n",
      "formats : 1\n",
      "structures : 1\n",
      "companies : 1\n",
      "need : 1\n",
      "consider : 1\n",
      "based : 1\n",
      "type : 1\n",
      "needs : 1\n",
      "captured : 1\n",
      "management : 1\n",
      "teams : 1\n",
      "help : 1\n",
      "set : 1\n",
      "standards : 1\n",
      "around : 2\n",
      "structure : 1\n",
      "facilitate : 1\n",
      "workflows : 1\n",
      "deep : 2\n",
      "models : 1\n",
      "this : 3\n",
      "stage : 1\n",
      "includes : 2\n",
      "cleaning : 1\n",
      "deduplicating : 1\n",
      "transforming : 1\n",
      "combining : 1\n",
      "etl : 1\n",
      "extract : 1\n",
      "transform : 1\n",
      "load : 1\n",
      "jobs : 1\n",
      "or : 3\n",
      "other : 4\n",
      "integration : 1\n",
      "technologies : 1\n",
      "preparation : 1\n",
      "essential : 1\n",
      "for : 7\n",
      "promoting : 1\n",
      "quality : 1\n",
      "before : 1\n",
      "loading : 1\n",
      "into : 1\n",
      "warehouse : 1\n",
      "lake : 1\n",
      "repository : 1\n",
      "analysis : 2\n",
      "here : 1\n",
      "scientists : 2\n",
      "conduct : 1\n",
      "exploratory : 1\n",
      "examine : 1\n",
      "biases : 1\n",
      "patterns : 1\n",
      "ranges : 1\n",
      "distributions : 1\n",
      "values : 1\n",
      "within : 2\n",
      "exploration : 1\n",
      "drives : 1\n",
      "hypothesis : 1\n",
      "generation : 1\n",
      "a/b : 1\n",
      "testing : 1\n",
      "also : 1\n",
      "allows : 1\n",
      "determine : 1\n",
      "relevance : 1\n",
      "use : 2\n",
      "modeling : 1\n",
      "efforts : 1\n",
      "predictive : 1\n",
      "and/or : 1\n",
      "depending : 1\n",
      "model : 1\n",
      "accuracy : 1\n",
      "become : 1\n",
      "allowing : 1\n",
      "drive : 1\n",
      "scalability : 1\n",
      "communicate : 1\n",
      "finally : 1\n",
      "presented : 1\n",
      "reports : 1\n",
      "visualizations : 2\n",
      "make : 1\n",
      "insights—and : 1\n",
      "their : 1\n",
      "impact : 1\n",
      "business—easier : 1\n",
      "decision-makers : 1\n",
      "understand : 1\n",
      "language : 1\n",
      "r : 1\n",
      "python : 1\n",
      "components : 1\n",
      "generating : 1\n",
      "; : 1\n",
      "alternately : 1\n",
      "dedicated : 1\n",
      "visualization : 1\n"
     ]
    }
   ],
   "source": [
    "# Importem les llibreries necessàries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Fem una tokenització\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Fem una conversió a minúscules\n",
    "tokens = [word.lower() for word in tokens]\n",
    "\n",
    "# Fem el càlcul de freqüència de paraules\n",
    "word_freq = nltk.FreqDist(tokens)\n",
    "\n",
    "# Mostrem les paraules i les seves freqüències\n",
    "for word, freq in word_freq.items():\n",
    "    print(word, \":\", freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f2a46",
   "metadata": {},
   "source": [
    "Anem a explicar detalladament que hem fet. Primer, s'ha importat NLTK i el mòdul word_tokenize per a la tokenització del text. A continuació, s'ha aplicat la tokenització al text, dividint-lo en paraules individuals o \"tokens\". Després, aquestes paraules s'han convertit totes a minúscules per estandarditzar-les i evitar duplicacions per diferències en majúscules o minúscules. Finalment, s'ha calculat la freqüència de cada paraula utilitzant FreqDist de NLTK, que proporciona un recompte de quants cops apareix cada paraula en el text. Finalment, s'han mostrat les paraules i les seves freqüències associades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a355da7",
   "metadata": {},
   "source": [
    "També podem crear un dataframe de Pandas per mostrar la llista de paraules de manera més organitzada i llegible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d030011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paraula</th>\n",
       "      <th>Freqüència</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>,</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>the</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>to</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>of</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>for</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paraula  Freqüència\n",
       "2       data          40\n",
       "9          ,          40\n",
       "36         .          19\n",
       "7        and          18\n",
       "46       the          16\n",
       "26        to          12\n",
       "49        of           9\n",
       "194      for           7\n",
       "3    science           6\n",
       "62         a           6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertim a DataFrame\n",
    "df = pd.DataFrame(word_freq.items(), columns=['Paraula', 'Freqüència'])\n",
    "\n",
    "# Ordenem les dades per freqüència en ordre descendent\n",
    "df = df.sort_values(by='Freqüència', ascending=False)\n",
    "\n",
    "# Mostrem els primers resultats del dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a7e78",
   "metadata": {},
   "source": [
    "# Exercici 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c896d79",
   "metadata": {},
   "source": [
    "<b> Treu les stopwords i realitza stemming al teu conjunt de dades.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188cc053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', '?', 'Data', 'science', 'combines', 'math', 'statistics', ',', 'specialized', 'programming', ',', 'advanced', 'analytics', ',', 'artificial', 'intelligence', '(', 'AI', ')', ',', 'machine', 'learning', 'specific', 'subject', 'matter', 'expertise', 'uncover', 'actionable', 'insights', 'hidden', 'organization', '’', 'data', '.', 'insights', 'used', 'guide', 'decision', 'making', 'strategic', 'planning', '.', 'accelerating', 'volume', 'data', 'sources', ',', 'subsequently', 'data', ',', 'made', 'data', 'science', 'one', 'fastest', 'growing', 'field', 'across', 'every', 'industry', '.', 'result', ',', 'surprise', 'role', 'data', 'scientist', 'dubbed', '“', 'sexiest', 'job', '21st', 'century', '”', 'Harvard', 'Business', 'Review', '(', 'link', 'resides', 'outside', 'IBM', ')', '.', 'Organizations', 'increasingly', 'reliant', 'interpret', 'data', 'provide', 'actionable', 'recommendations', 'improve', 'business', 'outcomes', '.', 'data', 'science', 'lifecycle', 'involves', 'various', 'roles', ',', 'tools', ',', 'processes', ',', 'enables', 'analysts', 'glean', 'actionable', 'insights', '.', 'Typically', ',', 'data', 'science', 'project', 'undergoes', 'following', 'stages', ':', 'Data', 'ingestion', ':', 'lifecycle', 'begins', 'data', 'collection', '--', 'raw', 'structured', 'unstructured', 'data', 'relevant', 'sources', 'using', 'variety', 'methods', '.', 'methods', 'include', 'manual', 'entry', ',', 'web', 'scraping', ',', 'real-time', 'streaming', 'data', 'systems', 'devices', '.', 'Data', 'sources', 'include', 'structured', 'data', ',', 'customer', 'data', ',', 'along', 'unstructured', 'data', 'like', 'log', 'files', ',', 'video', ',', 'audio', ',', 'pictures', ',', 'Internet', 'Things', '(', 'IoT', ')', ',', 'social', 'media', ',', '.', 'Data', 'storage', 'data', 'processing', ':', 'Since', 'data', 'different', 'formats', 'structures', ',', 'companies', 'need', 'consider', 'different', 'storage', 'systems', 'based', 'type', 'data', 'needs', 'captured', '.', 'Data', 'management', 'teams', 'help', 'set', 'standards', 'around', 'data', 'storage', 'structure', ',', 'facilitate', 'workflows', 'around', 'analytics', ',', 'machine', 'learning', 'deep', 'learning', 'models', '.', 'stage', 'includes', 'cleaning', 'data', ',', 'deduplicating', ',', 'transforming', 'combining', 'data', 'using', 'ETL', '(', 'extract', ',', 'transform', ',', 'load', ')', 'jobs', 'data', 'integration', 'technologies', '.', 'data', 'preparation', 'essential', 'promoting', 'data', 'quality', 'loading', 'data', 'warehouse', ',', 'data', 'lake', ',', 'repository', '.', 'Data', 'analysis', ':', ',', 'data', 'scientists', 'conduct', 'exploratory', 'data', 'analysis', 'examine', 'biases', ',', 'patterns', ',', 'ranges', ',', 'distributions', 'values', 'within', 'data', '.', 'data', 'analytics', 'exploration', 'drives', 'hypothesis', 'generation', 'a/b', 'testing', '.', 'also', 'allows', 'analysts', 'determine', 'data', '’', 'relevance', 'use', 'within', 'modeling', 'efforts', 'predictive', 'analytics', ',', 'machine', 'learning', ',', 'and/or', 'deep', 'learning', '.', 'Depending', 'model', '’', 'accuracy', ',', 'organizations', 'become', 'reliant', 'insights', 'business', 'decision', 'making', ',', 'allowing', 'drive', 'scalability', '.', 'Communicate', ':', 'Finally', ',', 'insights', 'presented', 'reports', 'data', 'visualizations', 'make', 'insights—and', 'impact', 'business—easier', 'business', 'analysts', 'decision-makers', 'understand', '.', 'data', 'science', 'programming', 'language', 'R', 'Python', 'includes', 'components', 'generating', 'visualizations', ';', 'alternately', ',', 'data', 'scientists', 'use', 'dedicated', 'visualization', 'tools', '.']\n"
     ]
    }
   ],
   "source": [
    "# Importem les llibreries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Fem una tokenització\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Eliminem les stopwords\n",
    "stop_words = set(stopwords.words('english')) # Indiquem que l'idioma és l'anglès\n",
    "tokens_without_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "# Mostrem el resultat\n",
    "print(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d56c3",
   "metadata": {},
   "source": [
    "Ara farem una neteja i una lematització per tal de millorar la qualitat i la consistència del nostre conjunt de dades. La neteja eliminarà tot el soroll innecessari, com ara signes de puntuació i caràcters especials, assegurant que el text quedi lliure de distorsions i més enfocat per a l'anàlisi. La lematització, per la seva banda, normalitzarà les paraules a la seva forma bàsica i significativa, tractant les diferents formes d'una mateixa paraula com un únic ítem. Això és crucial per a una interpretació més precisa en anàlisis lingüístiques i semàntiques, especialment en tasques de classificació de textos, modelització de temes i mineria de text. Ambdues tècniques, neteja i lematització, són fonamentals per obtenir un conjunt de dades net, coherent i òptim per a qualsevol tipus d'anàlisi de processament de llenguatge natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d54df",
   "metadata": {},
   "source": [
    "Comencem eliminant els signes de puntuació i càracters no desitjats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265abfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'Data', 'science', 'combines', 'math', 'statistics', 'specialized', 'programming', 'advanced', 'analytics', 'artificial', 'intelligence', 'AI', 'machine', 'learning', 'specific', 'subject', 'matter', 'expertise', 'uncover', 'actionable', 'insights', 'hidden', 'organization', 'data', 'insights', 'used', 'guide', 'decision', 'making', 'strategic', 'planning', 'accelerating', 'volume', 'data', 'sources', 'subsequently', 'data', 'made', 'data', 'science', 'one', 'fastest', 'growing', 'field', 'across', 'every', 'industry', 'result', 'surprise', 'role', 'data', 'scientist', 'dubbed', 'sexiest', 'job', 'century', 'Harvard', 'Business', 'Review', 'link', 'resides', 'outside', 'IBM', 'Organizations', 'increasingly', 'reliant', 'interpret', 'data', 'provide', 'actionable', 'recommendations', 'improve', 'business', 'outcomes', 'data', 'science', 'lifecycle', 'involves', 'various', 'roles', 'tools', 'processes', 'enables', 'analysts', 'glean', 'actionable', 'insights', 'Typically', 'data', 'science', 'project', 'undergoes', 'following', 'stages', 'Data', 'ingestion', 'lifecycle', 'begins', 'data', 'collection', 'raw', 'structured', 'unstructured', 'data', 'relevant', 'sources', 'using', 'variety', 'methods', 'methods', 'include', 'manual', 'entry', 'web', 'scraping', 'streaming', 'data', 'systems', 'devices', 'Data', 'sources', 'include', 'structured', 'data', 'customer', 'data', 'along', 'unstructured', 'data', 'like', 'log', 'files', 'video', 'audio', 'pictures', 'Internet', 'Things', 'IoT', 'social', 'media', 'Data', 'storage', 'data', 'processing', 'Since', 'data', 'different', 'formats', 'structures', 'companies', 'need', 'consider', 'different', 'storage', 'systems', 'based', 'type', 'data', 'needs', 'captured', 'Data', 'management', 'teams', 'help', 'set', 'standards', 'around', 'data', 'storage', 'structure', 'facilitate', 'workflows', 'around', 'analytics', 'machine', 'learning', 'deep', 'learning', 'models', 'stage', 'includes', 'cleaning', 'data', 'deduplicating', 'transforming', 'combining', 'data', 'using', 'ETL', 'extract', 'transform', 'load', 'jobs', 'data', 'integration', 'technologies', 'data', 'preparation', 'essential', 'promoting', 'data', 'quality', 'loading', 'data', 'warehouse', 'data', 'lake', 'repository', 'Data', 'analysis', 'data', 'scientists', 'conduct', 'exploratory', 'data', 'analysis', 'examine', 'biases', 'patterns', 'ranges', 'distributions', 'values', 'within', 'data', 'data', 'analytics', 'exploration', 'drives', 'hypothesis', 'generation', 'testing', 'also', 'allows', 'analysts', 'determine', 'data', 'relevance', 'use', 'within', 'modeling', 'efforts', 'predictive', 'analytics', 'machine', 'learning', 'deep', 'learning', 'Depending', 'model', 'accuracy', 'organizations', 'become', 'reliant', 'insights', 'business', 'decision', 'making', 'allowing', 'drive', 'scalability', 'Communicate', 'Finally', 'insights', 'presented', 'reports', 'data', 'visualizations', 'make', 'impact', 'business', 'analysts', 'understand', 'data', 'science', 'programming', 'language', 'R', 'Python', 'includes', 'components', 'generating', 'visualizations', 'alternately', 'data', 'scientists', 'use', 'dedicated', 'visualization', 'tools']\n"
     ]
    }
   ],
   "source": [
    "# Eliminem els signes de puntuació i nombres\n",
    "tokens_without_punctuation = [word for word in tokens_without_stopwords if word.isalpha()]\n",
    "\n",
    "# Mostrem el resultat \n",
    "print(tokens_without_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca000e25",
   "metadata": {},
   "source": [
    "Ara fem una lematització:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa70d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'science', 'Data', 'science', 'combine', 'math', 'statistic', 'specialized', 'programming', 'advanced', 'analytics', 'artificial', 'intelligence', 'AI', 'machine', 'learning', 'specific', 'subject', 'matter', 'expertise', 'uncover', 'actionable', 'insight', 'hidden', 'organization', 'data', 'insight', 'used', 'guide', 'decision', 'making', 'strategic', 'planning', 'accelerating', 'volume', 'data', 'source', 'subsequently', 'data', 'made', 'data', 'science', 'one', 'fastest', 'growing', 'field', 'across', 'every', 'industry', 'result', 'surprise', 'role', 'data', 'scientist', 'dubbed', 'sexiest', 'job', 'century', 'Harvard', 'Business', 'Review', 'link', 'resides', 'outside', 'IBM', 'Organizations', 'increasingly', 'reliant', 'interpret', 'data', 'provide', 'actionable', 'recommendation', 'improve', 'business', 'outcome', 'data', 'science', 'lifecycle', 'involves', 'various', 'role', 'tool', 'process', 'enables', 'analyst', 'glean', 'actionable', 'insight', 'Typically', 'data', 'science', 'project', 'undergoes', 'following', 'stage', 'Data', 'ingestion', 'lifecycle', 'begin', 'data', 'collection', 'raw', 'structured', 'unstructured', 'data', 'relevant', 'source', 'using', 'variety', 'method', 'method', 'include', 'manual', 'entry', 'web', 'scraping', 'streaming', 'data', 'system', 'device', 'Data', 'source', 'include', 'structured', 'data', 'customer', 'data', 'along', 'unstructured', 'data', 'like', 'log', 'file', 'video', 'audio', 'picture', 'Internet', 'Things', 'IoT', 'social', 'medium', 'Data', 'storage', 'data', 'processing', 'Since', 'data', 'different', 'format', 'structure', 'company', 'need', 'consider', 'different', 'storage', 'system', 'based', 'type', 'data', 'need', 'captured', 'Data', 'management', 'team', 'help', 'set', 'standard', 'around', 'data', 'storage', 'structure', 'facilitate', 'workflow', 'around', 'analytics', 'machine', 'learning', 'deep', 'learning', 'model', 'stage', 'includes', 'cleaning', 'data', 'deduplicating', 'transforming', 'combining', 'data', 'using', 'ETL', 'extract', 'transform', 'load', 'job', 'data', 'integration', 'technology', 'data', 'preparation', 'essential', 'promoting', 'data', 'quality', 'loading', 'data', 'warehouse', 'data', 'lake', 'repository', 'Data', 'analysis', 'data', 'scientist', 'conduct', 'exploratory', 'data', 'analysis', 'examine', 'bias', 'pattern', 'range', 'distribution', 'value', 'within', 'data', 'data', 'analytics', 'exploration', 'drive', 'hypothesis', 'generation', 'testing', 'also', 'allows', 'analyst', 'determine', 'data', 'relevance', 'use', 'within', 'modeling', 'effort', 'predictive', 'analytics', 'machine', 'learning', 'deep', 'learning', 'Depending', 'model', 'accuracy', 'organization', 'become', 'reliant', 'insight', 'business', 'decision', 'making', 'allowing', 'drive', 'scalability', 'Communicate', 'Finally', 'insight', 'presented', 'report', 'data', 'visualization', 'make', 'impact', 'business', 'analyst', 'understand', 'data', 'science', 'programming', 'language', 'R', 'Python', 'includes', 'component', 'generating', 'visualization', 'alternately', 'data', 'scientist', 'use', 'dedicated', 'visualization', 'tool']\n"
     ]
    }
   ],
   "source": [
    "# Importem el mòdul/llibreria\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Inicialitzem el lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apliquem la lematització\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens_without_punctuation]\n",
    "\n",
    "# Mostrem el resultat\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d8183",
   "metadata": {},
   "source": [
    "# Exercici 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edae856",
   "metadata": {},
   "source": [
    "<b> Realitza un anàlisi de sentiment al teu conjunt de dades. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8fc065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.005, 'neu': 0.925, 'pos': 0.07, 'compound': 0.9719}\n"
     ]
    }
   ],
   "source": [
    "# Importem la llibreria/mòdul\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Inicialitzem l'analitzador de sentiments\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Obtenim les puntuacions de sentiments\n",
    "sentiment_scores = sia.polarity_scores(text)\n",
    "\n",
    "# Mostrem el resultat\n",
    "print(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b21609",
   "metadata": {},
   "source": [
    "El resultat de l'anàlisi de sentiments de l'article sobre ciència de dades de la pàgina corporativa d'IBM indica una predominança de tonalitat neutra amb una tendència lleugerament positiva. \n",
    "\n",
    "La puntuació negativa és extremadament baixa (neg: 0.005), mostrant una quasi absència de sentiments negatius, el que és esperable en un contingut corporatiu informatiu. La majoria del contingut és classificat com neutre (neu: 0.925), reflectint l'enfocament objectiu i factual que és l'esperat en publicacions corporatives i articles tècnics. Tot i això, hi ha una presència notable de sentiments positius (pos: 0.07), que podria reflectir un to optimista sobre el tema de la ciència de dades. La puntuació composta (compound: 0.9719) reafirma aquesta tonalitat globalment positiva, tot i que lleugera, la qual pot ser el resultat de l'expressió d'entusiasme o confiança en les capacitats i impacte de la ciència de dades segons la perspectiva d'IBM. \n",
    "\n",
    "Aquest tipus de tonalitat és comú en materials corporatius que busquen destacar els punts forts i les innovacions de l'empresa de manera subtil però efectiva. En resum, un to afirmatiu en un article corporatiu serveix no només per informar, sinó també per influir positivament en la percepció del lector sobre el tema, en aquest cas, la ciència de dades, i potencialment sobre la pròpia empresa, IBM. Aquest tipus de to és sovint utilitzat per posicionar una empresa com a líder de pensament o a l'avantguarda d'un camp específic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
